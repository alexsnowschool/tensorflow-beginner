{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN with Fashion MNIST.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvQkfv8iqH8g"
      },
      "source": [
        "<figure>\n",
        "<center>\n",
        "<img src='https://raw.githubusercontent.com/alexsnowschool/TensorFlow-Beginner/main/project_img.png' width = '800px'/>\n",
        "</center>        \n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRPLzh3hlCK5"
      },
      "source": [
        "#Exploring Fashion MNIST Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXA3ntrEqopc"
      },
      "source": [
        "<figure>\n",
        "<center>\n",
        "<img src='https://www.researchgate.net/profile/Greeshma_K_V/publication/340299295/figure/fig1/AS:875121904476163@1585656729996/Fashion-MNIST-Dataset-Images-with-Labels-and-Description-II-LITERATURE-REVIEW-In-image.jpg' width = '500px'/>\n",
        "</center>        \n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNQWttYbmbPv"
      },
      "source": [
        "**Load Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8jib0w6mgc6"
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist \n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ydjrn5xmrGD"
      },
      "source": [
        "**Shape of data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kabSKeg0mtgw",
        "outputId": "700cbd39-0c11-4bcf-db4f-9c50eb3e863b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print('X_train shape: ', x_train.shape)\n",
        "print('Y_train shape: ', y_train.shape)\n",
        "print('X_test shape: ', x_test.shape)\n",
        "print('Y_test shape: ', y_test.shape)\n",
        "print('Labels of Train Data: ', set(y_train))\n",
        "print('Labels of  Test Data: ', set(y_test))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape:  (60000, 28, 28)\n",
            "Y_train shape:  (60000,)\n",
            "X_test shape:  (10000, 28, 28)\n",
            "Y_test shape:  (10000,)\n",
            "Labels of Train Data:  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "Labels of  Test Data:  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbodB_yTm4v3"
      },
      "source": [
        "**Plotting image with matplotlib**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbW2sk_jk9cc",
        "outputId": "e6ec69e6-9857-441f-ada9-75cea552a337",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "# plotting image \n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "images = [x_train[0], x_test[0], x_train[1], x_test[1]]\n",
        "titles = [y_train[0], y_test[0], y_train[1], y_test[1]]\n",
        "\n",
        "for i in range(4):\n",
        "  plt.subplot(2, 2, i+1), plt.imshow(images[i], 'gray')\n",
        "  plt.title(titles[i])\n",
        "  plt.xticks([]), plt.yticks([])\n",
        "\n",
        "plt.show()\n",
        "# label 9 = ankle boots, label 0 = tshirt/top, label 2 = pullover"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I03VV--U4rV8"
      },
      "source": [
        "#Training Model on Fashion MNIST Using 3 layers (Input Layer, hidden layer, output layer) without using CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOY3cOx74jsC",
        "outputId": "160a5092-2853-4763-f186-c483e3d4a00d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# import libraries\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# load dataset\n",
        "mnist_fashion = tf.keras.datasets.fashion_mnist\n",
        "(train_img, train_label), (test_img, test_label) = mnist_fashion.load_data()\n",
        "\n",
        "# normalize data\n",
        "train_img = train_img / 255.0\n",
        "test_img = test_img / 255.0\n",
        "\n",
        "# build model\n",
        "model = Sequential([\n",
        "        Flatten(input_shape=(28, 28)),\n",
        "        Dense(128, activation=tf.nn.relu),\n",
        "        Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# complie model \n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# fit model\n",
        "model.fit(train_img, train_label, epochs=5)\n",
        "\n",
        "# evaluation \n",
        "test_loss = model.evaluate(test_img, test_label)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4966 - accuracy: 0.8264\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3762 - accuracy: 0.8651\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3386 - accuracy: 0.8759\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3124 - accuracy: 0.8853\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2967 - accuracy: 0.8900\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3470 - accuracy: 0.8753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-kYVbJ37ho6"
      },
      "source": [
        "**Without CNN, we get 89% accuracy on training and 87% accuracy on testing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK8O9boUW18B"
      },
      "source": [
        "#Improving Computer Vision Accuracy using CNN\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShC5C7P1Evr_",
        "outputId": "f7c32ab2-b584-4cc7-da76-3e995a2d058c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "# import libraries\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# load dataset\n",
        "mnist_fashion = tf.keras.datasets.fashion_mnist\n",
        "(train_img, train_label), (test_img, test_label) = mnist_fashion.load_data()\n",
        "\n",
        "# normalize data\n",
        "train_img = train_img.reshape(60000, 28, 28, 1)\n",
        "train_img = train_img / 255.0\n",
        "\n",
        "test_img = test_img.reshape(10000, 28, 28, 1)\n",
        "test_img = test_img / 255.0\n",
        "\n",
        "# build model\n",
        "model = Sequential([\n",
        "        Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Flatten(),\n",
        "        Dense(128, activation=tf.nn.relu),\n",
        "        Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# complie model \n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# fit model\n",
        "model.fit(train_img, train_label, epochs=5)\n",
        "\n",
        "# evaluation \n",
        "test_loss = model.evaluate(test_img, test_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               204928    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4406 - accuracy: 0.8410\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2937 - accuracy: 0.8917\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2474 - accuracy: 0.9081\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2167 - accuracy: 0.9201\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1883 - accuracy: 0.9295\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2580 - accuracy: 0.9054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv8hK_B89PuT"
      },
      "source": [
        "**Without CNN, we get 89% accuracy on training and 87% accuracy on testing**\n",
        "\n",
        "**With CNN, we get 92% accuracy on training and 90% accuracy on testing**"
      ]
    }
  ]
}